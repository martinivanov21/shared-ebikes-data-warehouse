{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T09:27:15.285011Z",
     "start_time": "2025-05-22T09:27:15.181384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta import configure_spark_with_delta_pip\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "import ConnectionConfig as cc\n",
    "cc.setupEnvironment()"
   ],
   "id": "d4649419149aff8f",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T09:27:27.555905Z",
     "start_time": "2025-05-22T09:27:16.145205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#active session\n",
    "spark = cc.startLocalCluster(\"DIM_LOCK\",4)\n",
    "spark.getActiveSession()"
   ],
   "id": "ed3b8c701f44c05c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1e72cf13d10>"
      ],
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Martin:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DIM_LOCK</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T09:27:45.811167Z",
     "start_time": "2025-05-22T09:27:44.961025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cc.set_connectionProfile(\"VeloBike\")\n",
    "print(cc.create_jdbc())\n",
    "locks_df = spark.read.format(\"jdbc\").option(\"driver\" , \"org.postgresql.Driver\").option(\"url\", cc.create_jdbc()).option(\"dbtable\", \"locks\").option(\"user\", cc.get_Property(\"username\")).option(\"password\", cc.get_Property(\"password\"))    .load()\n",
    "\n",
    "stations_df = spark.read.format(\"jdbc\").option(\"driver\" , \"org.postgresql.Driver\").option(\"url\", cc.create_jdbc()).option(\"dbtable\", \"stations\").option(\"user\", cc.get_Property(\"username\")).option(\"password\", cc.get_Property(\"password\"))    .load()\n",
    "\n",
    "\n",
    "# reneming the columns so there is no conflict\n",
    "stations_df = stations_df.withColumnRenamed(\"stationid\", \"station_id\")\n",
    "\n"
   ],
   "id": "50140e5d7f9423ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jdbc:postgresql://localhost:5433/velodb\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T09:27:47.834473Z",
     "start_time": "2025-05-22T09:27:47.744935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "joined_df = locks_df.join(\n",
    "    stations_df,\n",
    "    locks_df.stationid == stations_df.station_id,\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "# Instead of grouping by station_id, keep each lock as a separate row\n",
    "# This way you can join with rides on lockid directly\n",
    "lock_dim_df = joined_df.select(\n",
    "    \"lockid\",\n",
    "    \"stationid\",\n",
    "    \"stationlocknr\",\n",
    "    \"street\",\n",
    "    \"number\",\n",
    "    \"zipcode\",\n",
    "    \"district\",\n",
    "    \"gpscoord\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# # Group by stationid to have one row per station\n",
    "# lock_dim_df = joined_df.groupBy(\"station_id\").agg(\n",
    "#     first(\"lockid\").alias(\"stationnr\"),\n",
    "#     first(\"street\").alias(\"street\"),\n",
    "#     first(\"number\").alias(\"number\"),\n",
    "#     first(\"zipcode\").alias(\"zipcode\"),\n",
    "#     first(\"district\").alias(\"district\"),\n",
    "#     first(\"gpscoord\").alias(\"gpscoord\")\n",
    "# )\n",
    "# lock_dim_df.show()\n"
   ],
   "id": "6d096df01ce6e527",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T09:27:51.977496Z",
     "start_time": "2025-05-22T09:27:49.199212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# the schema for the no locks rows\n",
    "schema = StructType([\n",
    "    StructField(\"lockid\", IntegerType(), True),\n",
    "    StructField(\"stationid\", IntegerType(), True),\n",
    "    StructField(\"stationlocknr\", IntegerType(), True),\n",
    "    StructField(\"street\", StringType(), True),\n",
    "    StructField(\"number\", StringType(), True),\n",
    "    StructField(\"zipcode\", StringType(), True),\n",
    "    StructField(\"district\", StringType(), True),\n",
    "    StructField(\"gpscoord\", StringType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "null_lock_row = Row(lockid=0, stationid=0, stationlocknr=None, street=None, number=None, zipcode=None, district=None, gpscoord=None)\n",
    "\n",
    "null_lock_df = spark.createDataFrame([null_lock_row], schema)\n",
    "\n",
    "\n",
    "final_lock_dim_df = lock_dim_df.union(null_lock_df)\n",
    "\n",
    "final_lock_dim_df.show()"
   ],
   "id": "961cfc229964b22a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-------------+-----------+------+-------+---------+-----------------+\n",
      "|lockid|stationid|stationlocknr|     street|number|zipcode| district|         gpscoord|\n",
      "+------+---------+-------------+-----------+------+-------+---------+-----------------+\n",
      "|    19|        2|            1| ONTBREKEND|    12|   2000|ANTWERPEN| (51.219,4.40405)|\n",
      "|    20|        2|            2| ONTBREKEND|    12|   2000|ANTWERPEN| (51.219,4.40405)|\n",
      "|    21|        2|            3| ONTBREKEND|    12|   2000|ANTWERPEN| (51.219,4.40405)|\n",
      "|     1|        1|            1|Meir (2000)|    84|   2000|ANTWERPEN|(51.2182,4.41241)|\n",
      "|     2|        1|            2|Meir (2000)|    84|   2000|ANTWERPEN|(51.2182,4.41241)|\n",
      "|     3|        1|            3|Meir (2000)|    84|   2000|ANTWERPEN|(51.2182,4.41241)|\n",
      "|     4|        1|            4|Meir (2000)|    84|   2000|ANTWERPEN|(51.2182,4.41241)|\n",
      "|     5|        1|            5|Meir (2000)|    84|   2000|ANTWERPEN|(51.2182,4.41241)|\n",
      "|     6|        1|            6|Meir (2000)|    84|   2000|ANTWERPEN|(51.2182,4.41241)|\n",
      "|     7|        1|            7|Meir (2000)|    84|   2000|ANTWERPEN|(51.2182,4.41241)|\n",
      "|     8|        1|            8|Meir (2000)|    84|   2000|ANTWERPEN|(51.2182,4.41241)|\n",
      "|     9|        1|            9|Meir (2000)|    84|   2000|ANTWERPEN|(51.2182,4.41241)|\n",
      "|    10|        1|           10|Meir (2000)|    84|   2000|ANTWERPEN|(51.2182,4.41241)|\n",
      "|    11|        1|           11|Meir (2000)|    84|   2000|ANTWERPEN|(51.2182,4.41241)|\n",
      "|    12|        1|           12|Meir (2000)|    84|   2000|ANTWERPEN|(51.2182,4.41241)|\n",
      "|    13|        1|           13|Meir (2000)|    84|   2000|ANTWERPEN|(51.2182,4.41241)|\n",
      "|    14|        1|           14|Meir (2000)|    84|   2000|ANTWERPEN|(51.2182,4.41241)|\n",
      "|    15|        1|           15|Meir (2000)|    84|   2000|ANTWERPEN|(51.2182,4.41241)|\n",
      "|    16|        1|           16|Meir (2000)|    84|   2000|ANTWERPEN|(51.2182,4.41241)|\n",
      "|    17|        1|           17|Meir (2000)|    84|   2000|ANTWERPEN|(51.2182,4.41241)|\n",
      "+------+---------+-------------+-----------+------+-------+---------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T09:28:04.303684Z",
     "start_time": "2025-05-22T09:27:54.406363Z"
    }
   },
   "cell_type": "code",
   "source": "final_lock_dim_df.count()",
   "id": "9486e2ab9fc90e8e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7543"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T09:28:33.523760Z",
     "start_time": "2025-05-22T09:28:10.500008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_lock_dim_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"dimLock\")\n",
    "final_lock_dim_df.repartition(1).write.format(\"parquet\").mode(\"overwrite\").saveAsTable(\"dimLock_pq\")\n"
   ],
   "id": "a0e5aadb848210fc",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T09:28:40.301522Z",
     "start_time": "2025-05-22T09:28:40.087864Z"
    }
   },
   "cell_type": "code",
   "source": "spark.stop()",
   "id": "677119bbe3f2fcb",
   "outputs": [],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
