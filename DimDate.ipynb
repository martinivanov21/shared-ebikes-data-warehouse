{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T09:22:48.581040Z",
     "start_time": "2025-05-22T09:22:48.416631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta import configure_spark_with_delta_pip\n",
    "import ConnectionConfig as cc\n",
    "cc.setupEnvironment()"
   ],
   "id": "c64593c34e423469",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T09:23:23.019636Z",
     "start_time": "2025-05-22T09:22:49.656714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#active session\n",
    "spark = cc.startLocalCluster(\"DIM_DATE\",4)\n",
    "spark.getActiveSession()"
   ],
   "id": "b887b01c6c6b9723",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x26cf47b6ed0>"
      ],
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Martin:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DIM_DATE</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T09:24:13.329338Z",
     "start_time": "2025-05-22T09:24:13.231365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "beginDate = '2015-09-22'\n",
    "endDate = '2025-12-31'\n",
    "\n",
    "df_SQL = spark.sql(f\"select explode(sequence(to_date('{beginDate}'), to_date('{endDate}'), interval 1 day)) as calendarDate, monotonically_increasing_id()+1 as dateSK \")\n",
    "\n",
    "\n",
    "df_SQL.createOrReplaceTempView(\"neededDates\")\n",
    "\n",
    "spark.sql(\"select * from neededDates\").show()"
   ],
   "id": "6b6c14007e7c8c9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|calendarDate|dateSK|\n",
      "+------------+------+\n",
      "|  2015-09-22|     1|\n",
      "|  2015-09-23|     2|\n",
      "|  2015-09-24|     3|\n",
      "|  2015-09-25|     4|\n",
      "|  2015-09-26|     5|\n",
      "|  2015-09-27|     6|\n",
      "|  2015-09-28|     7|\n",
      "|  2015-09-29|     8|\n",
      "|  2015-09-30|     9|\n",
      "|  2015-10-01|    10|\n",
      "|  2015-10-02|    11|\n",
      "|  2015-10-03|    12|\n",
      "|  2015-10-04|    13|\n",
      "|  2015-10-05|    14|\n",
      "|  2015-10-06|    15|\n",
      "|  2015-10-07|    16|\n",
      "|  2015-10-08|    17|\n",
      "|  2015-10-09|    18|\n",
      "|  2015-10-10|    19|\n",
      "|  2015-10-11|    20|\n",
      "+------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T09:24:16.044864Z",
     "start_time": "2025-05-22T09:24:15.933353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dimDate = spark.sql(\"select dateSK, calendarDate as date, year(calendarDate) as year, quarter(calendarDate) as QuarterOfYear, month(calendarDate) as month_nr, date_format(calendarDate,'MMMM') as month_name, date_format(calendarDate, 'EEEE') as day_name, dayofweek(calendarDate) AS day_nr, case when weekday(calendarDate) < 5 then 'Y' else 'N' end as IsWeekDay  from neededDates\")\n",
    "\n",
    "\n",
    "dimDate.show()"
   ],
   "id": "1b9e381a817e8e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----+-------------+--------+----------+---------+------+---------+\n",
      "|dateSK|      date|year|QuarterOfYear|month_nr|month_name| day_name|day_nr|IsWeekDay|\n",
      "+------+----------+----+-------------+--------+----------+---------+------+---------+\n",
      "|     1|2015-09-22|2015|            3|       9| September|  Tuesday|     3|        Y|\n",
      "|     2|2015-09-23|2015|            3|       9| September|Wednesday|     4|        Y|\n",
      "|     3|2015-09-24|2015|            3|       9| September| Thursday|     5|        Y|\n",
      "|     4|2015-09-25|2015|            3|       9| September|   Friday|     6|        Y|\n",
      "|     5|2015-09-26|2015|            3|       9| September| Saturday|     7|        N|\n",
      "|     6|2015-09-27|2015|            3|       9| September|   Sunday|     1|        N|\n",
      "|     7|2015-09-28|2015|            3|       9| September|   Monday|     2|        Y|\n",
      "|     8|2015-09-29|2015|            3|       9| September|  Tuesday|     3|        Y|\n",
      "|     9|2015-09-30|2015|            3|       9| September|Wednesday|     4|        Y|\n",
      "|    10|2015-10-01|2015|            4|      10|   October| Thursday|     5|        Y|\n",
      "|    11|2015-10-02|2015|            4|      10|   October|   Friday|     6|        Y|\n",
      "|    12|2015-10-03|2015|            4|      10|   October| Saturday|     7|        N|\n",
      "|    13|2015-10-04|2015|            4|      10|   October|   Sunday|     1|        N|\n",
      "|    14|2015-10-05|2015|            4|      10|   October|   Monday|     2|        Y|\n",
      "|    15|2015-10-06|2015|            4|      10|   October|  Tuesday|     3|        Y|\n",
      "|    16|2015-10-07|2015|            4|      10|   October|Wednesday|     4|        Y|\n",
      "|    17|2015-10-08|2015|            4|      10|   October| Thursday|     5|        Y|\n",
      "|    18|2015-10-09|2015|            4|      10|   October|   Friday|     6|        Y|\n",
      "|    19|2015-10-10|2015|            4|      10|   October| Saturday|     7|        N|\n",
      "|    20|2015-10-11|2015|            4|      10|   October|   Sunday|     1|        N|\n",
      "+------+----------+----+-------------+--------+----------+---------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T09:24:17.841855Z",
     "start_time": "2025-05-22T09:24:17.702265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_SparkSQL = df_SQL.withColumn(\"year\", date_format(\"calendarDate\",'yyyy')).withColumn(\"month\",date_format(\"calendarDate\",'MMMM')).withColumn(\"lastDayOfMonth\", expr(\"case when calendarDate = last_day (calendarDate) then 'Y' else 'N' end as IsLastDayOfMonth\"))\n",
    "\n",
    "df_SparkSQL.show()"
   ],
   "id": "63255b4735338e7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+----+---------+--------------+\n",
      "|calendarDate|dateSK|year|    month|lastDayOfMonth|\n",
      "+------------+------+----+---------+--------------+\n",
      "|  2015-09-22|     1|2015|September|             N|\n",
      "|  2015-09-23|     2|2015|September|             N|\n",
      "|  2015-09-24|     3|2015|September|             N|\n",
      "|  2015-09-25|     4|2015|September|             N|\n",
      "|  2015-09-26|     5|2015|September|             N|\n",
      "|  2015-09-27|     6|2015|September|             N|\n",
      "|  2015-09-28|     7|2015|September|             N|\n",
      "|  2015-09-29|     8|2015|September|             N|\n",
      "|  2015-09-30|     9|2015|September|             Y|\n",
      "|  2015-10-01|    10|2015|  October|             N|\n",
      "|  2015-10-02|    11|2015|  October|             N|\n",
      "|  2015-10-03|    12|2015|  October|             N|\n",
      "|  2015-10-04|    13|2015|  October|             N|\n",
      "|  2015-10-05|    14|2015|  October|             N|\n",
      "|  2015-10-06|    15|2015|  October|             N|\n",
      "|  2015-10-07|    16|2015|  October|             N|\n",
      "|  2015-10-08|    17|2015|  October|             N|\n",
      "|  2015-10-09|    18|2015|  October|             N|\n",
      "|  2015-10-10|    19|2015|  October|             N|\n",
      "|  2015-10-11|    20|2015|  October|             N|\n",
      "+------------+------+----+---------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T09:24:24.183608Z",
     "start_time": "2025-05-22T09:24:19.919454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dimDate.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"dimDate\")\n",
    "dimDate.repartition(1).write.format(\"parquet\").mode(\"overwrite\").saveAsTable(\"dimDate_pq\")"
   ],
   "id": "d4c8430c77557539",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T09:24:28.248208Z",
     "start_time": "2025-05-22T09:24:28.135091Z"
    }
   },
   "cell_type": "code",
   "source": "spark.stop()",
   "id": "5c03a29cd65ee53d",
   "outputs": [],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
